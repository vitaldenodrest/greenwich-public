{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314ddce9",
   "metadata": {},
   "source": [
    "Copyright (c) 2026 [Vital de Nodrest]\n",
    "\n",
    "The code (Python, shell and PowerShell cells) is under MIT license. Feel free to share and experiment! See LICENSE-CODE.txt in the project root for more information.\n",
    "\n",
    "Due to their time-consuming and didactic nature, text & image contents are under CC BY-NC-SA 4.0 license. Removal of the author's name or redistribution without credit is prohibited. See LICENSE-DOCS.txt in the project root for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d874a5",
   "metadata": {},
   "source": [
    "# Introduction to PINNs for Helmholtz problems\n",
    "\n",
    "This notebook aims at being a basic introduction to PINNs using the example of Helmholtz wave propagation problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c5352",
   "metadata": {},
   "source": [
    "## PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1baef",
   "metadata": {},
   "source": [
    "### Universal approximation theorem and PDE problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae7c5f",
   "metadata": {},
   "source": [
    "### Automatic differentiation and physical losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83f38a",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "You can use any recent Python environment to run this notebook (ipykernel will be required for interactive computing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa092c8",
   "metadata": {},
   "source": [
    "The following cells are necessary regardless of your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35ddf1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005613fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e05e1",
   "metadata": {},
   "source": [
    "The next subsections provide different configuration scripts depending on your device.\n",
    "\n",
    "You can uncomment and run the ones you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbaac5",
   "metadata": {},
   "source": [
    "### Apple Silicon, GPU\n",
    "\n",
    "Configuration for Apple Silicon devices running on GPU (mps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d8310e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"The MPS configuration worked.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS device not found. Performance might be impacted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19d7f2",
   "metadata": {},
   "source": [
    "### Linux, CUDA 12.6\n",
    "\n",
    "Configuration for Linux devices equipped with CUDA 12.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81d7909",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac6950d",
   "metadata": {},
   "source": [
    "### Linux, ROCm 7.1\n",
    "\n",
    "Configuration for Linux devices equipped with ROCm 7.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a75465",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision --index-url https://download.pytorch.org/whl/rocm7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d92a34",
   "metadata": {},
   "source": [
    "### Windows, CUDA 12.6\n",
    "\n",
    "Configuration for Windows devices equipped with CUDA 12.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f4e72",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d238aa7",
   "metadata": {},
   "source": [
    "### Windows, CPU\n",
    "\n",
    "Configuration for Windows users choosing to run on CPU. Performance might be impacted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfa931",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a4bc3",
   "metadata": {},
   "source": [
    "### Other devices\n",
    "\n",
    "If your situation doesn't fit any of the subsections, see the [PyTorch installation tutorial](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e204e16",
   "metadata": {},
   "source": [
    "## A 1D Helmholtz problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a22020",
   "metadata": {},
   "source": [
    "## Implementation (1D)\n",
    "\n",
    "The following chapter goes over the PyTorch implementation of a PINN solver for the Helmholtz problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!\n",
    "device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34659bce",
   "metadata": {},
   "source": [
    "### Neural network\n",
    "\n",
    "Let's initialize our neural network.\n",
    "\n",
    "A typical PINN takes the physical coordinates of the problem as an input and outputs the solution.\n",
    "In this example, the input is **x** (**1D** space variable) and the output is **u** (**1D** scalar output).\n",
    "\n",
    "There are many architectural possibilities for the neural network. The simplest choice is a uniform fully-connected neural network with tanh activation functions. By default, each neuron has a weight and a bias.\n",
    "\n",
    "We cannot use the tanh activation function after the last layer as we need a solution that can reach $1$ and $-1$.\n",
    "\n",
    "TODO plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb959f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_dim: int=1, output_dim: int=1, width: int=20, hidden_layers: int=3):\n",
    "        super().__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        layers = [nn.Linear(input_dim, width), nn.Tanh()] # input -> hidden layer 1\n",
    "        # hidden layer i -> hidden layer i+1\n",
    "        for _ in range(hidden_layers-1):\n",
    "            layers.append(nn.Linear(width, width))\n",
    "            layers.append(nn.Tanh())\n",
    "        layers.append(nn.Linear(width, output_dim)) # last hidden layer -> output\n",
    "        self.stack = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN(width=50)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a0c6d",
   "metadata": {},
   "source": [
    "Let's optimize our model parameters $\\theta$ (weight & biases) iteratively using the Adam algorithm with a learning rate of $.001$ to minimize the mean-square-error loss function:\n",
    "\n",
    "$$L_{\\text{MSE}} \\left(\\theta, (x_i)_{i=1}^N, (y_i)_{i=1}^N \\right) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( f_{\\theta}(x_i) - y_i \\right)^2 $$\n",
    "\n",
    "Where $f_{\\theta}$ is the model parametrized by the vector $\\theta$, and we consider $N$ training samples:\n",
    "- Training points $(x_i)_{i=1}^N$\n",
    "- Respective solutions $(y_i)_{i=1}^N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e65e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Loss\n",
    "loss = torch.nn.MSELoss() # the default reduction is \"mean\", dividing the loss by the number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e32c4",
   "metadata": {},
   "source": [
    "### PDE problem\n",
    "\n",
    "Let's implement our PDE problem in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126cf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_pde(X, U):\n",
    "    du_dx = torch.autograd.grad(outputs=U,\n",
    "                                inputs=X,\n",
    "                                grad_outputs=torch.ones_like(U), # Shape information for batches\n",
    "                                create_graph=True, # creating a graph for higher order derivatives\n",
    "                                retain_graph=True,\n",
    "                                )[0]\n",
    "    du_dxx = torch.autograd.grad(outputs=du_dx,\n",
    "                                 inputs=X,\n",
    "                                 grad_outputs=torch.ones_like(du_dx), # Shape information for batches\n",
    "                                 create_graph=True,\n",
    "    )[0]\n",
    "    return du_dxx + k**2 * U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_0(X, U):\n",
    "    du_dx = torch.autograd.grad(outputs=U,\n",
    "                                inputs=X,\n",
    "                                grad_outputs=torch.ones_like(U), # Shape information for batches\n",
    "                                create_graph=True,\n",
    "                                retain_graph=True,\n",
    "                                )[0]\n",
    "    return du_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_1(X, U):\n",
    "    du_dx = torch.autograd.grad(outputs=U,\n",
    "                                inputs=X,\n",
    "                                grad_outputs=torch.ones_like(U), # Shape information for batches\n",
    "                                create_graph=True,\n",
    "                                retain_graph=True,\n",
    "                                )[0]\n",
    "    return du_dx + k * torch.sin(k * torch.ones_like(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f10bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(x):\n",
    "    return torch.cos(k*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf19baa4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46df431",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training\n",
    "X_train_pde = torch.linspace(0, 1, 10 + 2, dtype=torch.float32, device=device)[1: -1].unsqueeze_(1)\n",
    "print(X_train_pde)\n",
    "X_train_0 = torch.tensor([0], dtype=torch.float32, device=device).unsqueeze_(1) # left boundary\n",
    "X_train_1 = torch.tensor([1], dtype=torch.float32, device=device).unsqueeze_(1) # right boundary\n",
    "### Validation\n",
    "X_validation_pde = torch.linspace(0.01, 0.99, 100, dtype=torch.float32, device=device).unsqueeze_(1)\n",
    "X_validation_0 = torch.tensor([0], dtype=torch.float32, device=device).unsqueeze_(1)\n",
    "X_validation_1 = torch.tensor([1], dtype=torch.float32, device=device).unsqueeze_(1)\n",
    "### Test\n",
    "X_test = torch.linspace(0, 1, 1000, dtype=torch.float32, device=device).unsqueeze_(1)\n",
    "U_test_exact = u(X_test)\n",
    "U_test_exact_norm = torch.linalg.vector_norm(U_test_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bc132",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35a3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOP\n",
    "\n",
    "num_epochs = 5000 # !!!\n",
    "train_losses = torch.zeros((3, num_epochs))\n",
    "validation_losses = torch.zeros((4, num_epochs))\n",
    "test_metrics = torch.zeros((num_epochs))\n",
    "\n",
    "best_model_state = None\n",
    "best_validation_loss = torch.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    ## Training phase\n",
    "    \n",
    "    ### Configuration\n",
    "    model.train()\n",
    "    optimizer.zero_grad() # reset previously accumulated gradients\n",
    "    \n",
    "    ### Optional reampling\n",
    "    #X_train_pde = torch.rand(size=(10,1)).unsqueeze_(1)\n",
    "    \n",
    "    ### Enable automatic differentiation for training and residuals audtodiff\n",
    "    X_train_pde.requires_grad_(True)\n",
    "    X_train_0.requires_grad_(True)\n",
    "    X_train_1.requires_grad_(True)\n",
    "    \n",
    "    ### Evaluate the model\n",
    "    U_train_pde = model(X_train_pde)\n",
    "    U_train_0 = model(X_train_0)\n",
    "    U_train_1 = model(X_train_1)\n",
    "    \n",
    "    ### Compute residuals\n",
    "    RES_train_pde = residual_pde(X_train_pde, U_train_pde)\n",
    "    RES_train_0 = residual_0(X_train_0, U_train_0)\n",
    "    RES_train_1 = residual_1(X_train_1, U_train_1)\n",
    "    \n",
    "    ### Evaluate losses and accumulate the parameter derivatives in place\n",
    "    train_loss_pde: torch.Tensor = loss(RES_train_pde, torch.zeros_like(RES_train_pde))\n",
    "    train_loss_pde.backward()\n",
    "    train_losses[0, epoch] = train_loss_pde.tolist()\n",
    "    \n",
    "    train_loss_0 = loss(RES_train_0, torch.zeros_like(RES_train_0))\n",
    "    train_loss_0.backward()\n",
    "    train_losses[1, epoch] = train_loss_0.tolist()\n",
    "    \n",
    "    train_loss_1 = loss(RES_train_1, torch.zeros_like(RES_train_1))\n",
    "    train_loss_1.backward()\n",
    "    train_losses[2, epoch] = train_loss_1.tolist()\n",
    "    \n",
    "    ### Perform optimizer step\n",
    "    optimizer.step()\n",
    "        \n",
    "        \n",
    "    ## Validation phase\n",
    "    \n",
    "    ### Configuration\n",
    "    model.eval()\n",
    "    \n",
    "    \"\"\"\n",
    "    torch.no_grad() cannot be used because computing \n",
    "    \"\"\"\n",
    "    \n",
    "    ### Enable automatic differentiation for residuals audtodiff\n",
    "    X_validation_pde.requires_grad_(True)\n",
    "    X_validation_0.requires_grad_(True)\n",
    "    X_validation_1.requires_grad_(True)\n",
    "        \n",
    "    ### Evaluate the model\n",
    "    U_validation_pde = model(X_validation_pde)\n",
    "    U_validation_0 = model(X_validation_0)\n",
    "    U_validation_1 = model(X_validation_1)\n",
    "    \n",
    "    ### Compute residuals\n",
    "    RES_validation_pde = residual_pde(X_validation_pde, U_validation_pde)\n",
    "    RES_validation_0 = residual_0(X_validation_0, U_validation_0)\n",
    "    RES_validation_1 = residual_1(X_validation_1, U_validation_1)\n",
    "    \n",
    "    ### Evaluate loss\n",
    "    validation_loss_total = 0\n",
    "    \n",
    "    validation_loss_pde: torch.Tensor = loss(RES_validation_pde, torch.zeros_like(RES_validation_pde))\n",
    "    validation_losses[0, epoch] = validation_loss_pde.tolist()\n",
    "    validation_loss_total += validation_loss_pde.tolist()\n",
    "    \n",
    "    validation_loss_0: torch.Tensor = loss(RES_validation_0, torch.zeros_like(RES_validation_0))\n",
    "    validation_losses[1, epoch] = validation_loss_0.tolist()\n",
    "    validation_loss_total += validation_loss_0.tolist()\n",
    "    \n",
    "    validation_loss_1: torch.Tensor = loss(RES_validation_1, torch.zeros_like(RES_validation_1))\n",
    "    validation_losses[2, epoch] = validation_loss_1.tolist()\n",
    "    validation_loss_total += validation_loss_1.tolist()\n",
    "    \n",
    "    \n",
    "    validation_losses[3, epoch] = validation_loss_total\n",
    "        \n",
    "    ### Save the best model\n",
    "    if validation_loss_total < best_validation_loss:\n",
    "        best_validation_loss = validation_loss_total\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        \n",
    "\n",
    "    ## Test phase (optional in the loop)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        U_test = model(X_test)\n",
    "        test_metrics[epoch] = (torch.linalg.vector_norm(U_test - U_test_exact) / U_test_exact_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45164db9",
   "metadata": {},
   "source": [
    "### Displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.plot(train_losses[0, :], label=']0,1[ residue')\n",
    "ax1.plot(train_losses[1, :], label='0 residue')\n",
    "ax1.plot(train_losses[2, :], label ='1 residue')\n",
    "ax1.plot(torch.sum(train_losses, dim=0), label='total residue')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_title('Training losses')\n",
    "ax1.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e910b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.plot(validation_losses[0, :], label=']0,1[ residue')\n",
    "ax2.plot(validation_losses[1, :], label='0 residue')\n",
    "ax2.plot(validation_losses[2, :], label='1 residue')\n",
    "ax2.plot(validation_losses[3, :], label='total residue')\n",
    "ax2.legend()\n",
    "ax2.set_title('Validation losses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ed1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.plot(test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eead3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Last model\n",
    "fig4, ax4 = plt.subplots()\n",
    "ax4.plot(X_test, U_test_exact)\n",
    "ax4.plot(X_test, U_test)\n",
    "\n",
    "u_min = torch.min(torch.min(U_test_exact), torch.min(U_test))\n",
    "u_max = torch.max(torch.max(U_test_exact), torch.max(U_test))\n",
    "for x in X_train_pde.detach().tolist() + X_train_0.detach().tolist() + X_train_1.detach().tolist():\n",
    "    ax4.plot([x]*2, [u_min, u_max], color='grey', linewidth=.3)\n",
    "\n",
    "last_str = f\"Last model test metric: {test_metrics[-1].tolist()}\"\n",
    "print(last_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b61772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Best model\n",
    "with torch.no_grad():\n",
    "    model.load_state_dict(best_model_state)\n",
    "    U_test = model(X_test)\n",
    "    best_test_metric = (torch.linalg.vector_norm(U_test - U_test_exact) / U_test_exact_norm)\n",
    "fig5, ax5 = plt.subplots()\n",
    "ax5.plot(X_test, U_test_exact)\n",
    "ax5.plot(X_test, U_test)\n",
    "best_str = f\"Best model test metric: {best_test_metric.tolist()}\"\n",
    "print(best_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5dcd5",
   "metadata": {},
   "source": [
    "## Further research..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenwich-public",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
